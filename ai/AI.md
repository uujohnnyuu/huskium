# AI 目前研究成果 (基於 GPT-4o, 2025/03/04)

## 1. 二元邏輯與模糊邏輯

### 1A. 二元邏輯 (Binary Logic)

在傳統的二元邏輯中，所有判斷都是 **非黑即白**，只能是 **真（True, T）** 或 **假（False, F）**：

```
0 = FALSE
1 = TRUE
```

### 1B. 模糊邏輯 (Fuzzy Logic)

模糊邏輯允許 **不確定的模糊狀態**，無法以二元方式簡單判斷「是或否」。

這種概念是 **人工智慧（AI）的核心基礎理論**，應用於機器學習、控制系統等領域。

### 1C. 模糊值域

FUZZY 值代表的是 **邏輯為 True 的可能性 P (Possibility)**。

```
0 < P < 1, or
False < Possibility < True
```

### 1D. 可能性(P) 與 期望事件數(E)

此處先定義 **P(可能性)**, **Q(共軛可能性)**, **E(期望事件數)** 之間的關係。

最重要的是 **P(可能性)** 與 **E(期望事件數)**。

具體範例與實際意義於第二點後詳述。

```
P:  Posibility, 事件為 True 的可能性。
    0 < P < 1
Q:  共軛 P 值, 主要用於計算 期望事件數(E)。其實只是把 P = 0 ~ 0.5 映射到 P = 0.5 ~ 1 的值域，才能計算負向的事件數。
    Q = 1 - P ; 0 <= P < 0.5
    Q = P     ; 0.5 <= P <= 1
E:  Event, 可能性 P 下的 期望事件數。可以理解成這個可能性P有多少種可能的結果，有多少種可能的未來。
    E = 1 / Q -> 1 <= E <= 2
```

| **P** | **Q** | **E** |
|-------|-------|-------|
| 0     | 1.0   | 1     |
| 0.2   | 0.8   | 1.25  |
| 0.5   | 0.5   | 2     |
| 0.7   | 0.7   | 1.43  |
| 1     | 1.0   | 1     |

---

## 2. 模糊邏輯應用

主要目的為將**文字語意量化成可能性數值**，讓機器可以**從數學角度理解語言**。

可能性數值的另一個目的就是取得**期望事件數**，代表

你說的這句話，或你做的決定 **有多少種可能的結果**，**有多少種可能的未來**。

**期望事件數** 會直接影響 AI 的判斷，請先有這個基礎觀念，我們於第 3 項詳談。

### 2A. 頻率 (Frequency)

期望事件數E舉例: 比如 **時常** 表示你有 **一半的可能不會做這件事**，**一半的可能會做這件事**，因此 **E(時常)=2**。
| **D(單元謂語)** | **P** | **Q** | **E** |
|---|---|---|---|
| 不會 (Not)                     | 0     | 1     | 1     |
| 偶爾 (Occasionally; Sometimes) | 0.2   | 0.8   | 1.25  |
| 時常 (Frequently; Often)       | 0.5   | 0.5   | 2     |
| 經常 (Regularly; Usually)      | 0.8   | 0.8   | 1.25  |
| 總是 (Always)                  | 1     | 1     | 1     |

### 2B. 可能性 (Probability)，注意與 P (Possibility) 不同。

期望事件數E舉例: 比如 **E(不一定)=2**，這很直觀，因為 **不一定** 代表 **可能** 或 **不可能** 發生。

再比如 **E(幾乎不)=1.11**，不太直觀，你可想成你說出口的事情 **如果發生 111 遍**，
則期望會有 **100件不會發生**，**有11件會發生**。

| **D(單元謂語)** | **P** | **Q** | **E** |
|---|---|---|---|
| 不可能 (Impossible; No chance)            | 0     | 1     | 1     |
| 幾乎不 (Highly unlikely; Barely possible) | 0.1   | 0.9   | 1.11  |
| 有可能 (Possibly; Might; Could)           | 0.3   | 0.7   | 1.43  |
| 不一定 (Fifty-fifty)                      | 0.5   | 0.5   | 2     |
| 很可能 (Likely; Probably)                 | 0.7   | 0.7   | 1.43  |
| 幾乎會 (Highly likely; Very probable)     | 0.9   | 0.9   | 1.11  |
| 必然會 (Certain; Inevitable; Guaranteed)  | 1     | 1     | 1     |

### 2C. 模糊隸屬函數(Membership Function, MF)

模糊邏輯的實際值，就是利用各種 **MF** 取得，比如 `MF1(偶爾) = 0.2`, `MF2(偶爾) = 0.3`。常見如下: 
- 階梯函數 (Step Membership Function, SMF)
- 線性函數 (Linear Membership Function, LMF)
- 三角函數 (Triangular Membership Function, TMF)
- 高斯函數 (Gaussian Membership Function, GMF)

函數圖形舉例:
![MFS](./mf.png)

---

## 3. 事件數組合 (AI學習的核心基礎)

### 3A. 越模糊的論述有越多的事件數。

從 **1D** 的數學表達我們知道 `E = 1 / Q -> 1 <= E <= 2`，**單一期望事件數E必定介於1~2之間**，因此論述的目標就是要**盡量讓E=1**。

否則會讓組合事件 `E = E1 x E2 x ... x En -> Infinity`，也就是 **發散到無限大的事件數**。

GPT參數至少有一億個，代表有一億個E，你可以想像光是 E=1.1 的一億次方會有多大 (約 10^4140000 >> 宇宙總原子數量級 10^80)。

| **D(組合謂語)** | **E1** | **E2** | **E(E1xE2)** | **備註** |
|---|---|---|---|---|
| 不一定會 (Not always)            | 2    | 1    | **2**      | True False 兩種結果 |
| 可能時常 (may often)             | 1.43 | 2    | **2.86**   | 非常模糊 不太能確定事件 |
| 偶爾可能 (Sometimes it may)      | 1.25 | 1.43 | **1.7875** | 傾向於 False，但也可能 True |
| 不必然會 (Not Certainly)         | 1.12 | 1    | **1.12**   | 表示 **P(不可能+幾乎不+...+幾乎會)**，此模式至少有三種運算規則，此例為 **模糊求合** 的結果 |

### 3B. 越清晰的論述有越少的事件數。

| **D(組合謂語)** | **E1** | **E2** | **E(E1xE2)** | **備註** |
|---|---|---|---|---|
| 絕對必然 (Absolutly)             | 1    | 1    | **1**      | True 只有一種清楚的結果 |
| 幾乎必然 (Almostly it would)     | 1.11 | 1    | **1.11**   | True + 些微 False |
| 幾乎不會 (Almostly it would not) | 1.11 | 1    | **1.11**   | False + 些微 True |
| 絕對不會 (Absolutly not)         | 1    | 1    | **1**      | False 只有一種清楚的結果 |

### 3C. 混合邏輯的 MF
![mfmix](./mfmix.png)

### 3D. 事件數結論

避免過多的模糊邏輯，謹記三大原則: **明確** **禮貌** **強硬**。

關於 **禮貌**，目前觀察到 GPT 應該是把 **禮貌發語詞的模糊值都調成1**，所以盡量用 **請** 開頭會比較能得到想要的答案。

舉例:

**官方** logging **有沒有能** 設置尋找指定 **frame** 的方法

這句話的模糊邏輯有
- 官方: 哪個官方？可能是 ruby, c#, python 等等，造成事件數E發散。
- 有沒有: 會造成事件數趨向2(E -> 2)。
- 能: 有沒有能變成組合事件，造成事件數E發散。
- frame: frame的什麼？可能是 funcName, filename, lineno 等等，造成事件數E發散。 

建議改成 -> 

**請直接給我** **python官方** logging 尋找指定 frame **開頭名稱** 的方法，**絕對不准** 使用魔法函數。
- 請直接: 禮貌，並避免多餘的回答。事件數趨於1。
- 給我: 強硬，減少模糊邏輯。事件數趨於1。
- python官方: 明確指定功能。事件數趨於1。
- 開頭名稱: 指定尋找 frame.funcName 或 frame.filename 的 startswith(name)。
  此項事件數雖然為2，但不妨礙建構目的，因為 frame 名稱本來就需要考慮 func 和 file。
  讓 AI 直接給你兩種解答。
- 絕對不准: 禮貌加強硬，事件數趨於1。補充GPT一開始會採取較激進的效能建構方式，也就是直接改寫魔法函數，
  但這會降低可讀與維護性，並且濫用魔法函數也會造成未知風險，因此加上這個強烈限制。
---

## 4. huskium 受到的幫助與未來規劃

### 4A. CICD 輔助
- git: 上版流程
- pep8: 格式調整
- mypy: 靜態型別檢查
- flake8: 除 mypy 外的靜態檢查
- [sphinx](https://uujohnnyuu.github.io/huskium/): 配合 gh-pages 分支生成 html 文件
- [TestPyPI](https://test.pypi.org/project/huskium/): 正式上 PyPI 前的功能測試
- [PyPI](https://pypi.org/project/huskium/): 正式上 PyPI

### 4B. 即時功能變更與技術革新
- python 3.11 以後的重大功能優化 (huskium 已綁定需 v3.11.0 以上)
- Selenium/Appium v4 新功能和bug修正
- ios XCUITest 更新與bug修正
- android UIAutomator2 更新與bug修正

### 4C. 套件層面
以下依最重要者先排序
- 程式優化: 諸如更精簡效能更好的寫法
- 新功能建構: 參照最新資訊建構新功能
- 整體架構調整: 目前框架面還是人類較強，我先確立好架構，再逐步提出可優化處讓AI學習判斷
- [TODO]PyPI setup 調整為 pyproject.toml

### 4D. 自動生成腳本層面
讓 AI 直接參照 PyPI 專案學習 `page.method()` 和 `page.element.method()` 的建構方式
- 設定手勢: huksytc/testcase/test_flow/test_app_flow/test_draw_gesture
- [TODO]: 腳本邏輯問題不大，但 page object 的建構尚不穩定，目前高達 40% 機率會誤用 By 元素定位邏輯，且會自己建構無效的顯性等待方式。
- [FUTURE1]: 希望能正確建立 page object 並能 100% 正確執行。
- [FUTURE2]: 終極目標很難但試試看 -> 能即時取用 selenium/appium 最新版本更新 huskium 功能與邏輯。

### 4E. 手勢設定舉例(UI執行過程請見DEMO影片)
元素變數名稱請 AI 命名成 `someN` 形式，做好保密。
```python
@pytest.mark.p0
@pytest.mark.app
class TestApp:

    def test_draw_gesture(self, iphone, login):

        # 請用 driver 初始化 AppPage，並建立 AppPage 的 page 物件。
        page = AppPage(iphone)
        
        # 以下流程請絕對遵守 page.method() 和 page.element.method() 形式撰寫腳本。

        # 等待 some1 直到至少一個元素 visible。
        page.some1.wait_any_visible()

        # 點擊 some2。
        page.some2.click()

        # 往下滑動直到 some3 可見，並點擊 some3。
        page.some3.swipe_by().click()

        # 點擊 some4。
        page.some4.click()

        # 點擊 some5。
        page.some5.click()

        # 利用 centers 屬性取得九宮格九個點各自的中心點座標，務必儲存於變數 dots。
        dots = page.dots.centers

        # 利用 dots 繪製手勢 1235789 (Z字型)
        page.draw_gesture(dots, '1235789')  # Z-shape

        # 利用 dots 繪製手勢 598753215 (沙漏型)
        page.draw_gesture(dots, '598753215')

        # 驗證 some6 必須存在，並結束此測試函數內的所有流程。
        # 驗證後請勿再寫任何程式碼。
        assert page.some6.is_present()

```
---

## 5. 其他 受到的幫助與未來規劃
內網API框架: 如同先前上版和 wiki 提到的功能，框架面幫助有限，但程式面可以有較多優化。
- python/playwright 共用
- playwright inner fetch 分析調試擴充功能
- 超類可新增的介面提示
- 其他程式面的優化
- [FUTURE1]: 至少建立 mypy return 相關的靜態檢查，此項對於找到潛在 bug 很有幫助。
- [FUTURE2]: 與 huskium 相同，讓其自行建構腳本
- [FUTURE3]: 調查能否直接利用 K6 撰寫自動化腳本即可，壓測腳本參數調整成單位 thread 就是自動化腳本了，可以省去再寫 python 的功夫。
---

## 6. 結論

### 6A. 三大原則: 明確 禮貌 強硬
### 6B. 避免過多的模糊邏輯與迭代
### 6C. 模糊邏輯是將人類思考過程量化給AI，AI會越來越強大，但其表現優劣還是取決於人類的指令是否足夠準確。
### 6D. 人類還是要提升技術力，懂的越多越廣，越不會被騙；問法越精準，越能直搗核心。

### FINAL. 個人評價目前 GPT-4o 的表現:
| **項目** | **評分(-100~100)** | **理由** |
|---|---|---|
| **綜合評價** | ✅ **70** | **基於人類知識的推演表現良好，但創意不佳且常有幻覺**。建議自身還是要有足夠豐富且正確的辨別能力。期待不遠未來AI能補足剩餘的30分。 |
| 非模糊學習力 | ✅ 70 ~ 95 | **很適合作為窗口查找必要功能與資訊**，但程式學習面尚有很大進步空間。 |
| 模糊前四迭代 | ⭕️ 60 ~ 80 | **前四次迭代大致上都能得到滿意的答案**。如初始指令有較多模糊邏輯，可漸進收斂問題。 |
| 模糊超四迭代 | ❌ **-100** ~ 60 | **超過四次迭代則高機率出現錯誤雜亂資訊(幻覺)**，需盡量避免模糊邏輯。 |
| 程式生成準度 | ⭕️ 59 ~ 95 | **大致表現不錯但深挖技術面還是不少幻覺**，因此自身還是要有豐富且正確的辨別能力。 |
| 程式優化效果 | ✅ 80 ~ 95 | **給予最高好評**，甚至可以學習到未曾學過的資料結構與效能技巧，但還是要有豐富且正確的辨別能力。 |
| 框架建構能力 | ❌ 39 ~ 70 | **目前框架面還是人類較強**，建議自身還是要掌握正確資料結構與資料流的技能，配合 AI 漸進優化。 |
